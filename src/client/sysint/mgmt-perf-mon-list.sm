/* 
 * (C) 2003 Clemson University and The University of Chicago 
 *
 * See COPYING in top-level directory.
 */

/** \file
 *  \ingroup mgmtint
 *
 *  PVFS2 management interface routines for obtaining server performance
 *  statistics.  This is used primarily for monitoring purposes.
 */

#include <string.h>
#include <assert.h>

#include "client-state-machine.h"
#include "state-machine-fns.h"
#include "pvfs2-debug.h"
#include "job.h"
#include "gossip.h"
#include "str-utils.h"
#include "pvfs2-mgmt.h"
#include "pint-servreq.h"
#include "pint-cached-config.h"
#include "PINT-reqproto-encode.h"

extern job_context_id pint_client_sm_context;

/* state function prototypes */
static int mgmt_perf_mon_list_setup_msgpair(
    PINT_client_sm *sm_p, job_status_s *js_p);
static int mgmt_perf_mon_list_cleanup(
    PINT_client_sm *sm_p, job_status_s *js_p);

static int perf_mon_list_comp_fn(
    void* v_p, struct PVFS_server_resp *resp_p, int i);

%%

machine pvfs2_client_mgmt_perf_mon_list_sm(
    setup_msgpair,
    xfer_msgpair,
    cleanup)
{
    state setup_msgpair
    {
        run mgmt_perf_mon_list_setup_msgpair;
        success => xfer_msgpair;
        default => cleanup;
    }

    state xfer_msgpair
    {
        jump pvfs2_msgpairarray_sm;
        default => cleanup;
    }

    state cleanup
    {
        run mgmt_perf_mon_list_cleanup;
        default => terminate;
    }
}

%%

/** Initiate retrieval of performance statistics from a list of servers.
 */
PVFS_error PVFS_imgmt_perf_mon_list(
    PVFS_fs_id fs_id,
    PVFS_credentials *credentials,
    struct PVFS_mgmt_perf_stat **perf_matrix,
    uint64_t *end_time_ms_array,
    PVFS_BMI_addr_t *addr_array,
    uint32_t* next_id_array,
    int server_count,
    int history_count,
    PVFS_error_details *details,
    PVFS_mgmt_op_id *op_id,
    void *user_ptr)
{
    PINT_client_sm *sm_p = NULL;

    gossip_debug(GOSSIP_CLIENT_DEBUG,
                 "PVFS_imgmt_perf_mon_list entered\n");

    if ((server_count < 1) || (history_count < 1) || !perf_matrix ||
        !addr_array || !end_time_ms_array)
    {
	return -PVFS_EINVAL;
    }

    sm_p = (PINT_client_sm *) malloc(sizeof(*sm_p));
    if (sm_p == NULL)
    {
        return -PVFS_ENOMEM;
    }
    memset(sm_p, 0, sizeof(*sm_p));

    PINT_init_msgarray_params(&sm_p->msgarray_params);
    PINT_init_sysint_credentials(sm_p->cred_p, credentials);
    sm_p->u.perf_mon_list.fs_id = fs_id;
    sm_p->u.perf_mon_list.perf_matrix = perf_matrix;
    sm_p->u.perf_mon_list.server_count = server_count;
    sm_p->u.perf_mon_list.history_count = history_count;
    sm_p->u.perf_mon_list.addr_array = addr_array;
    sm_p->u.perf_mon_list.next_id_array = next_id_array;
    sm_p->u.perf_mon_list.end_time_ms_array = end_time_ms_array;
    sm_p->u.perf_mon_list.details = details;

    sm_p->msgarray_count = server_count;
    sm_p->msgarray = (PINT_sm_msgpair_state *)malloc(
        server_count * sizeof(PINT_sm_msgpair_state));
    if (sm_p->msgarray == NULL)
    {
        PVFS_util_release_credentials(sm_p->cred_p);
        free(sm_p);
        return -PVFS_ENOMEM;
    }

    return PINT_client_state_machine_post(
        sm_p, PVFS_MGMT_PERF_MON_LIST, op_id, user_ptr);
}

/** Obtain performance statistics from a list of servers.
 */
PVFS_error PVFS_mgmt_perf_mon_list(
    PVFS_fs_id fs_id,
    PVFS_credentials *credentials,
    struct PVFS_mgmt_perf_stat **perf_matrix,
    uint64_t *end_time_ms_array,
    PVFS_BMI_addr_t *addr_array,
    uint32_t* next_id_array,
    int server_count,
    int history_count,
    PVFS_error_details *details)
{
    PVFS_error ret = -PVFS_EINVAL, error = 0;
    PVFS_mgmt_op_id op_id;

    gossip_debug(GOSSIP_CLIENT_DEBUG,
                 "PVFS_mgmt_perf_mon_list entered\n");
    
    ret = PVFS_imgmt_perf_mon_list(
        fs_id, credentials, perf_matrix, end_time_ms_array,
        addr_array, next_id_array, server_count, history_count,
        details, &op_id, NULL);

    if (ret)
    {
        PVFS_perror_gossip("PVFS_imgmt_perf_mon_list call", ret);
        error = ret;
    }
    else
    {
        ret = PINT_mgmt_wait(op_id, "perf_mon_list", &error);
        if (ret)
        {
            PVFS_perror_gossip("PVFS_mgmt_wait call", ret);
            error = ret;
        }
    }
    
    gossip_debug(GOSSIP_CLIENT_DEBUG,
                 "PVFS_mgmt_perf_mon_list completed\n");

    PINT_mgmt_release(op_id);
    return error;
}

static int mgmt_perf_mon_list_setup_msgpair(PINT_client_sm *sm_p,
					    job_status_s *js_p)
{
    int i = 0;
    PINT_sm_msgpair_state *msg_p = NULL;

    /* setup msgpair array */
    for (i=0; i < sm_p->msgarray_count; i++)
    {
	msg_p = &sm_p->msgarray[i];

	PINT_SERVREQ_MGMT_PERF_MON_FILL(
            msg_p->req,
            *sm_p->cred_p,
            sm_p->u.perf_mon_list.next_id_array[i],
            sm_p->u.perf_mon_list.history_count);

	msg_p->fs_id = sm_p->u.perf_mon_list.fs_id;
	msg_p->handle = PVFS_HANDLE_NULL;
	msg_p->retry_flag = PVFS_MSGPAIR_RETRY;
	msg_p->comp_fn = perf_mon_list_comp_fn;
	msg_p->svr_addr = sm_p->u.perf_mon_list.addr_array[i];
    }

    /* immediate return: next state jumps to msgpairarray machine */
    js_p->error_code = 0;
    return 1;
}

static int mgmt_perf_mon_list_cleanup(PINT_client_sm *sm_p,
				      job_status_s *js_p)
{
    int i = 0, errct = 0;
    PVFS_error error = js_p->error_code;

    /* store server-specific errors if requested and present */
    if ((error != 0) && (sm_p->u.perf_mon_list.details != NULL))
    {
	sm_p->u.perf_mon_list.details->count_exceeded = 0;

	for(i = 0; i < sm_p->u.perf_mon_list.server_count; i++)
        {
	    if (sm_p->msgarray[i].op_status != 0)
	    {
		if (errct <
                    sm_p->u.perf_mon_list.details->count_allocated)
		{
		    sm_p->u.perf_mon_list.details->error[errct].error =
                        sm_p->msgarray[i].op_status;
		    sm_p->u.perf_mon_list.details->error[errct].addr =
                        sm_p->msgarray[i].svr_addr;
		    errct++;
		}
		else
		{
		    sm_p->u.perf_mon_list.details->count_exceeded = 1;
		}
	    }
	}
	sm_p->u.perf_mon_list.details->count_used = errct;
	error = -PVFS_EDETAIL;
    }

    if (sm_p->msgarray && (sm_p->msgarray != &sm_p->msgpair))
    {
	free(sm_p->msgarray);
    }

    sm_p->error_code  = error;
    sm_p->op_complete = 1;

    return 0;
}

static int perf_mon_list_comp_fn(void* v_p,
				 struct PVFS_server_resp *resp_p,
				 int i)
{
    int j = 0;
    PINT_client_sm *sm_p = (PINT_client_sm *) v_p;

    /* if this particular request was successful, then store the 
     * performance information in an array to be returned to caller
     */
    if (sm_p->msgarray[i].op_status == 0)
    {
	sm_p->u.perf_mon_list.next_id_array[i] = 
	    resp_p->u.mgmt_perf_mon.suggested_next_id;
	sm_p->u.perf_mon_list.end_time_ms_array[i] =
	    resp_p->u.mgmt_perf_mon.end_time_ms;
	memcpy(sm_p->u.perf_mon_list.perf_matrix[i],
	       resp_p->u.mgmt_perf_mon.perf_array,
	       resp_p->u.mgmt_perf_mon.perf_array_count
	       * sizeof(struct PVFS_mgmt_perf_stat));
    }
 
    /* if this is the last response, check all of the status values and 
     * return error code if any requests failed 
     */
    if (i == (sm_p->msgarray_count -1))
    {
	for (j=0; j < sm_p->msgarray_count; j++)
	{
	    if (sm_p->msgarray[j].op_status != 0)
	    {
		return(sm_p->msgarray[j].op_status);
	    }
	}
    }
    return 0;
}

/*
 * Local variables:
 *  mode: c
 *  c-indent-level: 4
 *  c-basic-offset: 4
 * End:
 *
 * vim: ft=c ts=8 sts=4 sw=4 expandtab
 */
