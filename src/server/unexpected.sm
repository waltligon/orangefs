/* 
 * (C) 2001 Clemson University and The University of Chicago 
 *
 * See COPYING in top-level directory.
 */
#include <stdio.h>
#include <string.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <unistd.h>
#include <fcntl.h>
#include <assert.h>

#include "pvfs2-server.h"
#include "pvfs2-internal.h"
#include "pvfs2-debug.h"
#include "quicklist.h"
#include "server-config.h"
#include "id-generator.h"
#include "sid.h"
#include "server-config-mgr.h"

#define PFI()                                                                \
    do                                                                       \
    {                                                                        \
        gossip_debug(GOSSIP_SERVER_DEBUG,                                    \
                     "function called: {%s}\n", __PRETTY_FUNCTION__);        \
        fflush(stdout);                                                      \
    } while(0)

/* TODO are these enum values okay? */
enum {
    LOCAL_OPERATION = 2,
    REMOTE_OPERATION = 3,
    OP_CANCELLED = 4
};

static int unexpected_replicate_comp_fn(void *v_p,
                                        struct PVFS_server_resp *resp_p,
                                        int index);

static int unexpected_tree_comp_fn(void *v_p,
                                   struct PVFS_server_resp *resp_p,
                                   int index);

%%

nested machine pvfs2_unexpected_local_sm
{
    state unexp_local_pre
    {
        run unexp_local_pre;
        default => unexp_local_start;
    }

    state unexp_local_start
    {
        switch;
        default => unexp_local_post;
    }

    state unexp_local_post
    {
        run unexp_local_post;
        default => terminate;
    }
}

nested machine pvfs2_unexpected_remote_sm
{
    state unexp_remote_pre
    {
        run unexp_remote_pre;
        default => unexp_remote_send;
    }

    state unexp_remote_send
    {
        jump pvfs2_msgpairarray_sm;
        default => unexp_remote_post;
    }

    state unexp_remote_post
    {
        run unexp_remote_post;
        default => terminate;
    }
}

machine pvfs2_unexpected_sm
{
    state unexpected_post
    {
        run unexpected_post;
        default => unexpected_replace;
    }

    state unexpected_replace
    {
        run unexpected_replace;
        OP_CANCELLED => unexpected_terminate;
        default => unexpected_pjmp;
    }

    state unexpected_pjmp
    {
        pjmp unexpected_pjmp_setup
        {
            LOCAL_OPERATION => pvfs2_unexpected_local_sm;
            REMOTE_OPERATION => pvfs2_unexpected_remote_sm;
        }
        default => unexpected_pjmp_cleanup;
    }

    state unexpected_pjmp_cleanup
    {
        run unexpected_pjmp_cleanup;
        default => unexpected_terminate;
    }

    state unexpected_terminate
    {
        run unexpected_terminate;
        default => terminate;
    }
}

%%

/* ------------------ COMPLETION FUNCTIONS --------------------- */

static int unexpected_replicate_comp_fn(void *v_p,
                                        struct PVFS_server_resp *resp_p,
                                        int index)
{
    /* This will be the appropriate place to signal completions of
     * replica updates if we want to return early.  We can also signal
     * completion of a replica read in the event it is faster than any
     * other - we can ignore other results.  Not exactly sure how that
     * will fit in.  - WBL
     */
    PFI();
    return 0;
}

static int unexpected_tree_comp_fn(void *v_p,
                                   struct PVFS_server_resp *resp_p,
                                   int index)
{
    /* This will be the appropriate place to signal completions of
     * replica updates if we want to return early.  We can also signal
     * completion of a replica read in the event it is faster than any
     * other - we can ignore other results.  Not exactly sure how that
     * will fit in.  - WBL
     */
    PFI();
    return 0;
}

/* ---------------------- STATE ACTIONS ------------------------ */

/* unexpected_post()
 *
 * Post an unexpected receive
 */
static PINT_sm_action unexpected_post(struct PINT_smcb *smcb,
                                      job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -PVFS_EINVAL;
    PFI();

    /*
     * TODO: Consider the optimization of enabling immediate
     * completion in this part of the code (see the mailing list
     * thread from Feb. 2003 on pvfs2-internal).
     *
     * note: unexp_bmi_buff is really a struct that describes an
     * unexpected message (it is an output parameter).
     */
    ret = job_bmi_unexp(&s_op->unexp_bmi_buff,
                        smcb,
                        0,
                        js_p,
                        &s_op->unexp_id,
                        JOB_NO_IMMED_COMPLETE,
                        server_job_context);

    if(ret == SM_ACTION_COMPLETE)
    {
        PVFS_perror_gossip("Error: job_bmi_unexp failure", ret);
        return SM_ACTION_TERMINATE;
    }
    gossip_ldebug(GOSSIP_UNEXP_DEBUG, "DEFERRING!\n");
    return SM_ACTION_DEFERRED;
}

/* unexpected_replace()
 *
 * Starts a replacement unexpected request
 */
static PINT_sm_action unexpected_replace(struct PINT_smcb *smcb,
                                         job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -PVFS_EINVAL;
    PFI();

    /* If op was cancelled, print WARNING */
    if (s_op->op_cancelled)
    {
        gossip_ldebug(GOSSIP_UNEXP_DEBUG,
                      "INFO: op_cancelled, terminating sm!\n");
        js_p->error_code = OP_CANCELLED;
        return SM_ACTION_COMPLETE;
    }

    /* Remove s_op from posted_sop_list */
    qlist_del(&s_op->next);

    /* start replacement unexpected recv */
    ret = server_post_unexpected_recv();
    if (ret < 0)
    {
        /* TODO: do something here, the return value was
         * not being checked for failure before.  I just
         * put something here to make it exit for the
         * moment.  -Phil
         */
        PVFS_perror_gossip("pvfs2_unexpected_sm.unexpected_replace: "
                           "server_post_unexpected_recv() returned an error: ",
                           ret);
    }
    js_p->error_code = 0;
    return SM_ACTION_COMPLETE;
}

static PINT_sm_action unexpected_pjmp_setup(struct PINT_smcb *smcb,
                                            job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    struct PINT_server_op *local_op_frame = NULL;
    struct PINT_server_op *remote_op_frame = NULL;
    struct server_configuration_s *server_config_p = NULL;
    struct PINT_server_req_ctrl req_ctrl;
    int ret = -PVFS_EINVAL;
    int remote_op_cnt = 0;
    int remote_op = 0;

    PFI();

    server_config_p = PINT_server_config_mgr_get_config();
    gossip_ldebug(GOSSIP_UNEXP_DEBUG,
                  "server_config_p->host_index = %d\n",
                  server_config_p->host_index);

    /* If op was cancelled, kill the SM */
    if (s_op->op_cancelled)
    {
        return SM_ACTION_TERMINATE;
    }

    /* Decode request */
    ret = PINT_decode(s_op->unexp_bmi_buff.buffer,
                      PINT_DECODE_REQ,
                      &s_op->decoded,
                      s_op->unexp_bmi_buff.addr,
                      s_op->unexp_bmi_buff.size);

    if (ret == -PVFS_EPROTONOSUPPORT)
    {
        /* we have a protocol mismatch of some sort; try to trigger a
         * response that gives a helpful error on client side even
         * though we can't interpret what the client was asking for
         */
        //ret = PINT_smcb_set_op(smcb, PVFS_SERV_PROTO_ERROR);
        
        /* for now return an error */
        PVFS_perror_gossip("Error: PINT_decode nosupport", ret);
        js_p->error_code = ret;
        return SM_ACTION_COMPLETE;
    }
    else if (ret != 0)
    {
        PVFS_perror_gossip("Error: PINT_decode failure", ret);
        js_p->error_code = ret;
        return SM_ACTION_COMPLETE;
    }
                 
    s_op->req  = (struct PVFS_server_req *)s_op->decoded.buffer;
    smcb->op = s_op->req->op;
    s_op->op = s_op->req->op;

    gossip_debug(GOSSIP_UNEXP_DEBUG, "Received a request with op=%d\n",
                                     s_op->op);

    if (s_op->op < 2 || s_op->op > PVFS_SERV_NUM_OPS)
    {
        PVFS_perror_gossip("Error: Bad request op", ret);
    }

    PVFS_hint_add(&s_op->req->hints,
                  PVFS_HINT_SERVER_ID_NAME,
                  sizeof(uint32_t),
                  &server_config_p->host_index);

    PVFS_hint_add(&s_op->req->hints,
                  PVFS_HINT_OP_ID_NAME,
                  sizeof(uint32_t),
                  &s_op->req->op);


    /* Setup 1 local op */
    local_op_frame = (struct PINT_server_op *)
                             calloc(1, sizeof(struct PINT_server_op));
    if (!local_op_frame)
    {
        js_p->error_code = -PVFS_ENOMEM;
        return SM_ACTION_COMPLETE;
    }

    /* this is the original request so we copy the frame from the
     * original and push it onto the framestack
     */
    memcpy(local_op_frame, s_op, sizeof(struct PINT_server_op));
    gossip_ldebug(GOSSIP_UNEXP_DEBUG, "Pushing local op frame\n");
    s_op->num_pjmp_frames = 1;
    ret = PINT_sm_push_frame(smcb, LOCAL_OPERATION, local_op_frame);
    if(ret < 0)
    {
        gossip_lerr("unexpected_pjmp_setup failed to push frame for "
                    "local_op!\n");
    }

    /* Replicate and Tree are very similar so we share a lot of code */
    if ((s_op->req->ctrl.mode == PVFS_REQ_REPLICATE ||
         s_op->req->ctrl.mode == PVFS_REQ_TREE) &&
        s_op->req->ctrl.type == PVFS_REQ_PRIMARY)
    {
        /* This is a writing operation that must be replicated
         * and this is the original (primary) copy
         */
        /* The local op nolonger cares about this field, and the other
         * remote ops all need the same value.  Possibly TREE or other
         * protocls will do things differently
         */
        s_op->req->ctrl.type = PVFS_REQ_SECONDARY;

        memset(&req_ctrl, 0, sizeof(struct PINT_server_req_ctrl));
        PINT_server_req_get_ctrl(s_op->req, &req_ctrl);
        gossip_ldebug(GOSSIP_UNEXP_DEBUG,
                      "Ctrl sid_count = %d\n",req_ctrl.sid_count);
        gossip_ldebug(GOSSIP_UNEXP_DEBUG,
                      "Ctrl count = %d\n",req_ctrl.count);
        
        switch (s_op->req->ctrl.mode)
        {
        case PVFS_REQ_REPLICATE:
            /* subtract 1 for the local op */
            remote_op_cnt = req_ctrl.sid_count - 1;
            break;
        case PVFS_REQ_TREE:
            /* subtract 1 for the local op */
            remote_op_cnt = req_ctrl.count - 1;
            break;
        default:
            remote_op_cnt = 0;
            break;
        }

        /* This must be inside the "if" to work right otherwise we think
         * we need remote ops be really don't
         */
        if (remote_op_cnt <= 0)
        {
            /* normally replicate but there are no replicants so skip */
            goto noremote;
        }

        /* Allocate a structure to manage syncing the SMs */
        local_op_frame->join =
                (struct PINT_mpa_join *)calloc(1, sizeof(struct PINT_mpa_join));
#ifdef PVFS_MPA_JOIN
        gen_mutex_init(&local_op_frame->join);
#endif

        /* allocate frame for PJMP */
        remote_op_frame =
              (struct PINT_server_op *)calloc(1, sizeof(struct PINT_server_op));
        if (!remote_op_frame)
        {
            free(local_op_frame->join);
            free(local_op_frame);
            js_p->error_code = -PVFS_ENOMEM;
            return SM_ACTION_COMPLETE;
        }
        /* these are used to synchronize end of message with op */
        remote_op_frame->join = local_op_frame->join;

        /* set up frame and allocate msgpairs */
        PINT_msgpairarray_init(&remote_op_frame->msgarray_op, remote_op_cnt);
        remote_op_frame->msgarray_op.join = remote_op_frame->join;

        /* for each msgpair */
        for(remote_op = 0; remote_op < remote_op_cnt; remote_op++)
        {
            PINT_sm_msgpair_state *msg_p;
            msg_p = &remote_op_frame->msgarray_op.msgarray[remote_op];

            memcpy(&msg_p->req, s_op->req, sizeof(struct PVFS_server_req));
            PINT_copy_capability(&s_op->req->capability,
                                 &msg_p->req.capability);
            msg_p->msgclass = PVFS_IO_METADATA;
            msg_p->msgdir = PVFS_IO_WRITE;
            msg_p->fs_id = req_ctrl.fs_id;
            /* assuming normal case one handle for now */
            switch (s_op->req->ctrl.mode)
            {
            case PVFS_REQ_REPLICATE:
                msg_p->handle = *req_ctrl.handles;
                msg_p->sid_count = 1; /* each message handes 1 SID */
                msg_p->sid_index = 0;
                msg_p->sid_array = &req_ctrl.sids[remote_op + 1];
                msg_p->retry_flag = PVFS_MSGPAIR_RETRY;
                msg_p->comp_fn = unexpected_replicate_comp_fn;
                break;
            case PVFS_REQ_TREE:
                msg_p->handle = *req_ctrl.handles;
                msg_p->sid_count = req_ctrl.sid_count;
                msg_p->sid_index = 0;
                msg_p->sid_array = 
                           &req_ctrl.sids[(remote_op + 1) * req_ctrl.sid_count];
                msg_p->retry_flag = PVFS_MSGPAIR_RETRY;
                msg_p->comp_fn = unexpected_tree_comp_fn;
                break;
            default:
                break;
            }

            ret = PVFS_SID_get_addr(&msg_p->svr_addr, &msg_p->sid_array[0]);
            if (ret)
            {
                gossip_err("Failed to map meta server address\n");
                js_p->error_code = ret;
                return SM_ACTION_COMPLETE;
            }
        }
        /* now push remote ops frame */
        ret = PINT_sm_push_frame(smcb, REMOTE_OPERATION, remote_op_frame);
        gossip_ldebug(GOSSIP_UNEXP_DEBUG, "Pushing remote op frame\n");
        s_op->num_pjmp_frames += 1;
        if(ret < 0)
        {
            gossip_lerr("unexpected_pjmp_setup failed to push frame for "
                        "remote_ops!\n");
            js_p->error_code = ret;
            return SM_ACTION_COMPLETE;
        }
    }
    else if (s_op->req->ctrl.mode == PVFS_REQ_TREE &&
             s_op->req->ctrl.type == PVFS_REQ_PRIMARY)
    {
        /* The request has a list of handles and we need to copy
         * the request out to these.  We must determine the number
         * of copies to make.  The configuration tells us how many ways
         * to divide the list, and what a minimum list size is (below
         * which we do not divide)
         */
    }
    /* for now other modes are ignored, treated as single op */
noremote:
    /* Do nothing but just run the request as normal */

    js_p->error_code = 0;
    return SM_ACTION_COMPLETE;
}

static PINT_sm_action unexpected_pjmp_cleanup(struct PINT_smcb *smcb,
                                              job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    struct PINT_server_op *local_op = NULL;
    struct PINT_server_op *remote_op = NULL;
    int task_id;
    PVFS_error tmp_err = 0;
    int remaining = 0;
    PFI();

    gossip_ldebug(GOSSIP_UNEXP_DEBUG,
                  "s_op->num_pjmp_frames = %d\n",
                  s_op->num_pjmp_frames);

    assert(s_op->num_pjmp_frames > 0);

    for (; s_op->num_pjmp_frames > 1; s_op->num_pjmp_frames--)
    {
        gossip_ldebug(GOSSIP_UNEXP_DEBUG, "Poping a remote frame\n");
        remote_op = PINT_sm_pop_frame(smcb, &task_id, &tmp_err, &remaining);
        if (!remote_op)
        {
            gossip_ldebug(GOSSIP_UNEXP_DEBUG, "Failed to pop a frame\n");
            js_p->error_code = -1;
            return SM_ACTION_COMPLETE;
        }
        /* check for return codes and errors */
        /* comm failures need to be recorded at least */
        if (tmp_err < 0)
        {
            gossip_ldebug(GOSSIP_UNEXP_DEBUG, "Error code returned\n");
        }
        /* free up remote op */
        free(remote_op);
    }
    
    assert(s_op->num_pjmp_frames == 1);

    gossip_ldebug(GOSSIP_UNEXP_DEBUG, "Poping a local frame\n");
    local_op = PINT_sm_pop_frame(smcb, &task_id, &tmp_err, &remaining);
    if (!local_op)
    {
        gossip_err("Failed to pop a frame\n");
        js_p->error_code = -1;
        return SM_ACTION_COMPLETE;
    }
    gossip_ldebug(GOSSIP_UNEXP_DEBUG,
                  "popping frame\n"
                  "\ttask_id = %d\n"
                  "\ttmp_err = %d\n"
                  "\tremaining = %d\n",
                  task_id, tmp_err, remaining);

    /* check for return codes and errors */
    /* comm failures need to be recorded at least */
    if (tmp_err < 0)
    {
        gossip_err("Error code returned\n");
    }
    /* free up join structure */
    if (local_op->join)
    {
        if (local_op->join->count != 0)
        {
            gossip_err("local op has outstanding join references\n");
        }
        free(local_op->join);
    }
    else
    {   
        if (remote_op) /* should be NULL if no remote ops used */
        {
            gossip_err("local op missing join reference\n");
        }
    }
    /* free up local op */
    free(local_op);
    gossip_ldebug(GOSSIP_UNEXP_DEBUG, "Finished with unexpected PJMP\n");
    js_p->error_code = 0;
    return SM_ACTION_COMPLETE;
}

static PINT_sm_action unexpected_terminate(struct PINT_smcb *smcb,
                                           job_status_s *js_p)
{
    PFI();
    return SM_ACTION_TERMINATE;
}

/* ---------------------- PJMP STATE ACTIONS ------------------------ */

static PINT_sm_action unexp_remote_pre(struct PINT_smcb *smcb,
                                       job_status_s *js_p)
{
    PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret;
    PFI();

    /* set up to call MPA */
    ret = PINT_sm_push_frame(smcb, 0, &s_op->msgarray_op);

    js_p->error_code = ret;
    return SM_ACTION_COMPLETE;
}

static PINT_sm_action unexp_remote_post(struct PINT_smcb *smcb,
                                        job_status_s *js_p)
{
    PFI();
    js_p->error_code = 0;
    return SM_ACTION_TERMINATE;
}

static PINT_sm_action unexp_local_pre(struct PINT_smcb *smcb,
                                      job_status_s *js_p)
{
    PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    PVFS_id_gen_t tmp_id;
    PFI();

    /* Should we run prelude here - simplify SM code */

#if 0
    qlist_del(&s_op->next);
#endif

    qlist_add_tail(&s_op->next, &inprogress_sop_list);

    /* set timestamp on the beginning of this state machine */
    id_gen_fast_register(&tmp_id, s_op);

    if(s_op->req)
    {
        gossip_debug(GOSSIP_UNEXP_DEBUG, "client:%d, reqid:%d, rank:%d\n",
                     PINT_HINT_GET_CLIENT_ID(s_op->req->hints),
                     PINT_HINT_GET_REQUEST_ID(s_op->req->hints),
                     PINT_HINT_GET_RANK(s_op->req->hints));
        PINT_EVENT_START(PINT_sm_event_id,
                         server_controlling_pid,
                         NULL,
                         &s_op->event_id,
                         PINT_HINT_GET_CLIENT_ID(s_op->req->hints),
                         PINT_HINT_GET_REQUEST_ID(s_op->req->hints),
                         PINT_HINT_GET_RANK(s_op->req->hints),
                         PINT_HINT_GET_HANDLE(s_op->req->hints),
                         s_op->req->op);
        s_op->resp.op = s_op->req->op;
    }

    s_op->addr = s_op->unexp_bmi_buff.addr;
    s_op->tag  = s_op->unexp_bmi_buff.tag;

    /* the smcb->op and s_op->op are already set to the request 
     * next state is the switch that calls the proper state machine
     */

    js_p->error_code = 0;
    return SM_ACTION_COMPLETE;
}

static PINT_sm_action unexp_local_post(struct PINT_smcb *smcb,
                                       job_status_s *js_p)
{
    PINT_server_op *frame = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    PFI();
    /* check frame->join schedule hold if not ready */
    if (frame->join)
    {
#ifdef PVFS_MPA_JOIN
        gen_mutex_lock(&frame->join.mutex);
#endif
        /* insert join code here */
#ifdef PVFS_MPA_JOIN
        gen_mutex_unlock(&frame->join.mutex);
#endif
    }
    /* generate response */
    js_p->error_code = 0;
    return SM_ACTION_TERMINATE;
}

/*
 * Local variables:
 *  mode: c
 *  c-indent-level: 4
 *  c-basic-offset: 4
 * End:
 *
 * vim: ft=c ts=8 sts=4 sw=4 expandtab
 */
